{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Weather Data With Python\n",
    "\n",
    "---\n",
    "\n",
    "## *Contents*\n",
    "\n",
    " 1. [Introduction](#introduction)\n",
    " 2. [Part 1 - Find The Data](#part1)\n",
    " 3. [Part 2 - Extract The Data](#part2)\n",
    " 4. [Part 3 - Refine The Data](#part3)\n",
    " 5. [Part 4 - Export The Data](#part4)\n",
    " 6. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Introduction <a name='introduction'></a>\n",
    "Data is the oil of our information age. With it we can save lives, be more efficient and make more money. Data isn't just plucked from the internet in well organised, coherent files. The raw data needs to be *extracted*! That's what is happening here. **This project is about extracting information about the weather in Western Australia** using the Bureau of Meteorology's raw data. \n",
    "\n",
    "The end result of this data extraction will be a single CSV file with weather data about the rainfall, temperature and solar exposure of each weather station in WA. This will be done using a single Python executable (.py): this [Jupyter](http://jupyter.org/) notebook is only a proof of concept. Instead of collecting all of the data here in the notebook it will instead serve as an insight into my thought process. As such, I'll only be collecting rainfall data for a couple weather stations. \n",
    "\n",
    "All of the processes being used can be extended to gather data near-automatically in any (or all) states and territories in Australia. If you wish to collect data in your own country or region then this document can serve as guidlines as to how to solve similar problems you'll face.\n",
    "\n",
    "If you haven't figured it out so far, I'll be using [Python](https://www.python.org/) to extract my data. Python is a loosely-typed, object-orientated programming language built in C. A hugely beneficial feature of Python is its use of packages. In this projcet I'll be mainly using [urllib2](https://docs.python.org/2/library/urllib2.html), [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) and [Pandas](https://pandas.pydata.org/) plus help from some smaller packages like [zipfile](https://docs.python.org/2/library/zipfile.html) and [glob](https://docs.python.org/2/library/glob.html).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dirty Details\n",
    "The data originates from [The Bureau of Meteorology](http://www.bom.gov.au) in their [Climate Data database](http://www.bom.gov.au/climate/data/). As such I claim no rights to the data itself. Anything that is mine (like this notebook and my executable file) I am allowing free usage of in accordance to the licence in the repository. \n",
    "\n",
    "The CSV file being exported will be structured like so:\n",
    "\n",
    "```\n",
    "    Station Number, Date, Rainfall, Max Temp, Min Temp, Solar Exposure \n",
    "```\n",
    "\n",
    "Although this wont be the structure exported in this notebook (which is only done as a proof of concept), that will be the structure of the CSV file exported by the executable script.\n",
    "\n",
    "In this notebook I'll be using dataframes a lot. If you don't know much about Pandas, especially about their data structures, I recommend you read [this](https://pandas.pydata.org/pandas-docs/stable/dsintro.html) article in their documentation quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface - Importing Packages, Defining Global Variables\n",
    "First-things-first: import in the packages that will be used and define any global variables that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all of the goodies that I'll be using.\n",
    "\n",
    "# HTML Scraping Packages\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# File Manipulation Packages\n",
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "# Data Manipulation Packages\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, define some global variables that I'll be using.\n",
    "BOM_HOME = r'http://www.bom.gov.au'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1 - Find The Data <a name='part1'></a>\n",
    "Before we automate anything we should have a look at the data we are going to collect. Like I mentioned in the introduction the data is all found in the [Climate Data Database](http://www.bom.gov.au/climate/data/). So the first thing I did was go there, have a look at how to get the data manually and what kind of information we can collect.\n",
    "\n",
    "For each weather station you can request the:\n",
    "\n",
    " - Rainfall;\n",
    " - Max temperature;\n",
    " - Min temperature; or\n",
    " - Solar exposure.\n",
    "\n",
    "It makes sense to aim to collect all of these data points in the executable file. For this proof of concept, however, I'll just be focusing on the rainfall data. That way I can get the process working for one of the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring A Dataset\n",
    "Let's actually look at the data for one of the weather stations. The station I've chosen to experiment on is [Perth Airport's](http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=9021) weather station (station number 9021). On the webpage you can see towards the top right a link with the text \"All years of data\" which downloads a zipped directory with the following structure:\n",
    "\n",
    "```\n",
    "IDCJAC0009_9021_1800.zip\n",
    "|\n",
    "|---- IDCJAC0009_9021_1800_Data.csv\n",
    "`---- IDCJAC0009_9021_1800_Note.txt\n",
    "```\n",
    "\n",
    "I wont automate the extraction of the data just yet as I'm only exploring the database. So instead I've extracted the csv file manually, renamed it to 'station9021.csv' and imported it into a Pandas dataframe to visualise the data. You can see the last 5 rows of data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product code</th>\n",
       "      <th>Bureau of Meteorology station number</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Rainfall amount (millimetres)</th>\n",
       "      <th>Period over which rainfall was measured (days)</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27005</th>\n",
       "      <td>IDCJAC0009</td>\n",
       "      <td>9021</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27006</th>\n",
       "      <td>IDCJAC0009</td>\n",
       "      <td>9021</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27007</th>\n",
       "      <td>IDCJAC0009</td>\n",
       "      <td>9021</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27008</th>\n",
       "      <td>IDCJAC0009</td>\n",
       "      <td>9021</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27009</th>\n",
       "      <td>IDCJAC0009</td>\n",
       "      <td>9021</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Product code  Bureau of Meteorology station number  Year  Month  Day  \\\n",
       "27005   IDCJAC0009                                  9021  2017     12    8   \n",
       "27006   IDCJAC0009                                  9021  2017     12    9   \n",
       "27007   IDCJAC0009                                  9021  2017     12   10   \n",
       "27008   IDCJAC0009                                  9021  2017     12   11   \n",
       "27009   IDCJAC0009                                  9021  2017     12   12   \n",
       "\n",
       "       Rainfall amount (millimetres)  \\\n",
       "27005                            0.0   \n",
       "27006                            0.0   \n",
       "27007                            0.0   \n",
       "27008                            0.0   \n",
       "27009                            0.0   \n",
       "\n",
       "       Period over which rainfall was measured (days) Quality  \n",
       "27005                                             1.0       N  \n",
       "27006                                             1.0       N  \n",
       "27007                                             1.0       N  \n",
       "27008                                             1.0       N  \n",
       "27009                                             1.0       N  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.read_csv('ExploratoryData/station9021.csv').tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data columns are self-explainatory except for the last two. \n",
    "\n",
    "The second last column is the period time for collection. For the most part is will be over 1 day, as each day rainfall measurements are taken at 9am for the previous day. However, occassionally, there are some times where the rainfall was not collected that day. So instead of throwing out the data they \"carry it forward\" to the next day's measurement. So now the rainfall amount is linked to two (or more) days worth of rainfall instead of one.\n",
    "\n",
    "The last column is the quality of the data. This can be a little misleading as it doesn't actually tell you if the data collection was incorrect. Instead it flags whether or not the collection process has been audited and believed to have no significant errors associated with it. So if the row is flagged with \"Y\" then we can be confident that the data has been collected correctly and accurately. If it is flagged with \"N\" then it is likely that the data is correct, but that hasn't been confirmed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding The List of Stations\n",
    "Not all station numbers are being used up to 9021, nor are all 4-digit numbers in use. For example, station number 9 doesn't correspond to any station in Australia. Obviously that is a huge issue as we can't just assume a range of station numbers to collect our data over.\n",
    "\n",
    "Fortunately for me, BOM actually have a list of weather stations you can access! By going to the [Weather Station Directory](http://www.bom.gov.au/climate/data/stations/) you can request the list of weather station in Australia or any of it's States or Territories. I downloaded WA's list, which I've visualised the first 10 lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bureau of Meteorology product IDCJMC0014.                                       Produced: 23 Nov 2017\r\n",
      "West Australian stations measuring rainfall\r\n",
      "Site    Name                                     Lat       Lon      Start    End       Years   %  AWS\r\n",
      "-----------------------------------------------------------------------------------------------------\r\n",
      "   7118 ABBOTTS                                  -26.4000  118.4000 Sep 1898 Nov 1913    6.8   45   N\r\n",
      "  10258 ABERVON                                  -30.7833  117.9833 May 1968 Aug 1973    5.2   97   N\r\n",
      "   4000 ABYDOS                                   -21.4167  118.9333 Jul 1917 Dec 1974   40.0   70   N\r\n",
      "   4045 ABYDOS WOODSTOCK                         -21.6200  118.9550 Apr 1901 Sep 1997   65.2   67   N\r\n",
      "   9971 ACTON PARK                               -33.7845  115.4072 Nov 2000 Nov 2017   17.0   98   N\r\n",
      "   2046 ADA VALE                                 -16.9500  128.1000 Jan 1920 Mar 1925    4.8   92   N\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"ExploratoryData/weather_stations.txt\") as f:\n",
    "    head = [next(f) for _ in xrange(10)]\n",
    "print ''.join(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already you can see that this text file is formatted for humans to read, not computers. Fortunately each \"column\" is fixed width. Thus it is possible to convert it to a csv! Although this is possible in python to do this, the time I would have to invest getting it to work right is more effort then just passing it through excel.\n",
    "\n",
    "So that's what I did: I imported the text file into excel, deleted the heading, footer and styling before finally exporting it as a plain csv file. I visualised the end result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Years</th>\n",
       "      <th>%</th>\n",
       "      <th>AWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7118</td>\n",
       "      <td>ABBOTTS</td>\n",
       "      <td>-26.4000</td>\n",
       "      <td>118.4000</td>\n",
       "      <td>Sep 1898</td>\n",
       "      <td>Nov 1913</td>\n",
       "      <td>6.8</td>\n",
       "      <td>45</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10258</td>\n",
       "      <td>ABERVON</td>\n",
       "      <td>-30.7833</td>\n",
       "      <td>117.9833</td>\n",
       "      <td>May 1968</td>\n",
       "      <td>Aug 1973</td>\n",
       "      <td>5.2</td>\n",
       "      <td>97</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>ABYDOS</td>\n",
       "      <td>-21.4167</td>\n",
       "      <td>118.9333</td>\n",
       "      <td>Jul 1917</td>\n",
       "      <td>Dec 1974</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4045</td>\n",
       "      <td>ABYDOS WOODSTOCK</td>\n",
       "      <td>-21.6200</td>\n",
       "      <td>118.9550</td>\n",
       "      <td>Apr 1901</td>\n",
       "      <td>Sep 1997</td>\n",
       "      <td>65.2</td>\n",
       "      <td>67</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9971</td>\n",
       "      <td>ACTON PARK</td>\n",
       "      <td>-33.7845</td>\n",
       "      <td>115.4072</td>\n",
       "      <td>Nov 2000</td>\n",
       "      <td>Nov 2017</td>\n",
       "      <td>17.0</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Site              Name      Lat       Lon     Start       End  Years   %  \\\n",
       "0   7118           ABBOTTS -26.4000  118.4000  Sep 1898  Nov 1913    6.8  45   \n",
       "1  10258           ABERVON -30.7833  117.9833  May 1968  Aug 1973    5.2  97   \n",
       "2   4000            ABYDOS -21.4167  118.9333  Jul 1917  Dec 1974   40.0  70   \n",
       "3   4045  ABYDOS WOODSTOCK -21.6200  118.9550  Apr 1901  Sep 1997   65.2  67   \n",
       "4   9971        ACTON PARK -33.7845  115.4072  Nov 2000  Nov 2017   17.0  98   \n",
       "\n",
       "   AWS  \n",
       "0    N  \n",
       "1    N  \n",
       "2    N  \n",
       "3    N  \n",
       "4    N  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.read_csv('ExploratoryData/weather_stations.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the columns here are self-explainatory. However, the last two columns aren't as clear. After some quick Googling and tinkering with the data I figured out what they are:\n",
    " - **% (Percentage)**: This is the completeness of the data collected. 100% signifies no missing data points for its entire history.\n",
    " - **AWS**: This states wheter or not the weather station is an *automatic weather station*. You could probably trust the data more in these weather stations, but that would be something worth exploring further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2 -  Extract The Data <a name='part2'></a>\n",
    "Now we have a rough idea as to what the data looks like and where we can access it. The next step is to automate the data extraction process.\n",
    "\n",
    "The process is incredibly simple. There will simply be a for-loop that iterates over the station list and then, using that data, accesses each weather station's data file and downloads it. It's literally that simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing The Data For Each Weather Station\n",
    "The first thing we want to explore is exactly *how* we can get to each weather station's data using a script. My first thoughts were to automate the \"filling out\" of forms using a package like [Selenum](http://selenium-python.readthedocs.io/). However this process is excessively convoluted. Instead I decided to investigate if there are any patterns in the URL for each station to mimic in a script.\n",
    "\n",
    "Fortunatley for me I noticed something unique about the URL: it was formatted the exact same and there was only a query string that controled the view!\n",
    "\n",
    "### URL Query String\n",
    "Each weather station's data page can be reached by using the same directory and changing one parameter in the query string. I figured this out when I went to station 9021's data page and noticed the URL:\n",
    "\n",
    "> http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=9021\n",
    "\n",
    "which contains the variable \"p_stn_num\" as one of its parameters; that parameter controls what station's data is being shown. By simply changing that parameter we can reach different pages in the portal!\n",
    "\n",
    "If you'd like to verify my conclusion, I've written up a function that fetches the station's name purely by changing the end of the URL. If you tinker with the function enough you'll notice that not all station numbers correspond to an actual weather station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station 9030: Mundaring \n"
     ]
    }
   ],
   "source": [
    "def printStationName(station_num):\n",
    "    \"\"\"Prints the name fo the weather station with the given station number.\"\"\"\n",
    "    page = urllib2.urlopen(\n",
    "        r'http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=' \n",
    "        + str(station_num).zfill(6)\n",
    "    )\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    print \"Station %s:\" % station_num, soup.h2.string\n",
    "    return None \n",
    "\n",
    "printStationName(9030)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Clicking\" On The Download Link\n",
    "The next step is to make the computer \"click\" on the download link on each page to collect the data. Of course I won't actually get the computer to click on the link, but rather find that link and simply open it using urllib2.\n",
    "\n",
    "Below I've written up a short function that does exactly that. It creates the URL to the specific webpage, searches for the download link (which is structured the exact same on every page), opens that link and then saves it as a zip file in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downloadDataForStation(station_num, datadir='./', verbose=False):\n",
    "    \"\"\"Accesses BOM's data link for the given station and downloads the data as a zipped file.\"\"\"\n",
    "    \n",
    "    # First access the weather station's data page.\n",
    "    page = urllib2.urlopen(\n",
    "        r'http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=' \n",
    "        + str(station_num).zfill(6)\n",
    "    )\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    # Then find the download link for that page.\n",
    "    download_link_extension = soup.find('a', \n",
    "        {'title': \"Data file for daily rainfall data for all years\"}\n",
    "    )['href']\n",
    "    \n",
    "    # Open the download link (which is read as binary) and save it in the correct format (zip file).\n",
    "    data = urllib2.urlopen(str(BOM_HOME + download_link_extension))\n",
    "    with open(datadir+'station_%s.zip' % station_num, 'wb') as zipper:\n",
    "        zipper.write(data.read())\n",
    "    \n",
    "    # Finally, print a success message if verbose and return\n",
    "    if verbose: print \"Download for station %s was successful!\" % station_num\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to test the function on any station number you wish. I'm going to be consistent and download the data for station 9021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download for station 9021 was successful!\n"
     ]
    }
   ],
   "source": [
    "downloadDataForStation(9021, datadir='ExploratoryData/', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing In The Station List\n",
    "The hardest part about collecting the weather station data would be iterating over hundreds to thousands of station numbers to manually look for which exist. Fortunately I solved that problem in Part 1 of the notebook: we can simply import in the station list and iterate over the dataframe to collect our data.\n",
    "\n",
    "In Part 1 we found a human-readable text file that contained all of the stations in WA that collect information on rainfall. With forsight to this point, I then converted the text file into a machine-readable CSV to be imported into a Pandas dataframe. Let's replicate that last step now to refresh our memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Years</th>\n",
       "      <th>%</th>\n",
       "      <th>AWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7118</td>\n",
       "      <td>ABBOTTS</td>\n",
       "      <td>-26.4000</td>\n",
       "      <td>118.4000</td>\n",
       "      <td>Sep 1898</td>\n",
       "      <td>Nov 1913</td>\n",
       "      <td>6.8</td>\n",
       "      <td>45</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10258</td>\n",
       "      <td>ABERVON</td>\n",
       "      <td>-30.7833</td>\n",
       "      <td>117.9833</td>\n",
       "      <td>May 1968</td>\n",
       "      <td>Aug 1973</td>\n",
       "      <td>5.2</td>\n",
       "      <td>97</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>ABYDOS</td>\n",
       "      <td>-21.4167</td>\n",
       "      <td>118.9333</td>\n",
       "      <td>Jul 1917</td>\n",
       "      <td>Dec 1974</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4045</td>\n",
       "      <td>ABYDOS WOODSTOCK</td>\n",
       "      <td>-21.6200</td>\n",
       "      <td>118.9550</td>\n",
       "      <td>Apr 1901</td>\n",
       "      <td>Sep 1997</td>\n",
       "      <td>65.2</td>\n",
       "      <td>67</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9971</td>\n",
       "      <td>ACTON PARK</td>\n",
       "      <td>-33.7845</td>\n",
       "      <td>115.4072</td>\n",
       "      <td>Nov 2000</td>\n",
       "      <td>Nov 2017</td>\n",
       "      <td>17.0</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Site              Name      Lat       Lon     Start       End  Years   %  \\\n",
       "0   7118           ABBOTTS -26.4000  118.4000  Sep 1898  Nov 1913    6.8  45   \n",
       "1  10258           ABERVON -30.7833  117.9833  May 1968  Aug 1973    5.2  97   \n",
       "2   4000            ABYDOS -21.4167  118.9333  Jul 1917  Dec 1974   40.0  70   \n",
       "3   4045  ABYDOS WOODSTOCK -21.6200  118.9550  Apr 1901  Sep 1997   65.2  67   \n",
       "4   9971        ACTON PARK -33.7845  115.4072  Nov 2000  Nov 2017   17.0  98   \n",
       "\n",
       "   AWS  \n",
       "0    N  \n",
       "1    N  \n",
       "2    N  \n",
       "3    N  \n",
       "4    N  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df = pandas.read_csv('ExploratoryData/weather_stations.csv')\n",
    "station_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all I need to do is extract the first column to get all of the information I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7118\n",
      "10258\n",
      "4000\n",
      "4045\n",
      "9971\n"
     ]
    }
   ],
   "source": [
    "station_numbers = station_df['Site']\n",
    "for _, n in station_numbers.head().iteritems():\n",
    "    print n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which, as you can see, works like a charm.\n",
    "\n",
    "Since this notebook is only a proof of concept, I wont be downloading the data for all of the weather stations here. This section was only to show how it will be done in the executable and how it is possible to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3 - Refine The Data <a name='part3'></a>\n",
    "Now we have all of the data we can get down into the messy parts.\n",
    "\n",
    "The first step is the extract the data out of the zipped files into their own directories. Once that's done, we can focus on cleaning up and reducing the data to reduce the size it takes up and to make it easier to work with. Finally we want to demonstrate how we can centralise multiple station's data into a single dataframe.\n",
    "\n",
    "Something that I don't do in this notebook, but would worthwhile exploring, would be data validation. We should be checking how much data is missing at certain weather stations to ensure if we can truely trust the source. Other important considerations would be how many times measurements are \"carried forward\" and measured over two days instead of one. That will have huge problems with the accuracy of the data. In saying that however, right there is a great idea for a project: interpolate the missing data points using the surrounding weather stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzipping The Compressed Directory\n",
    "Before we can do anything with the data, we need to extract it out of the zipped file. Fortunately for me, python already has a package that unzips files: [zipfile](https://docs.python.org/2/library/zipfile.html). So unzipping the data is a really trivial problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip(zipfilename):\n",
    "    \"\"\"Unzips the directories.\"\"\"\n",
    "    basename = os.path.splitext(zipfilename)[0]\n",
    "    with zipfile.ZipFile(zipfilename, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've unzipped one of the data directories below so I can continue to work on it throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unzip(\"ExploratoryData/station_9021.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning & Reducing The Data\n",
    "Now that we can access the CSV files for each station, we want to go about reducing the amount of columns. I've done this in two ways: dropping columns that aren't any use and combining the date columns together into the dataframe's index. You can see how I've done this by referring to the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readStationCSV(stationcsv):\n",
    "    \"\"\"Pass in the station's CSV to return a cleaned dataframe.\"\"\"\n",
    "    df = pandas.read_csv(stationcsv)\n",
    "    \n",
    "    # Rename the columns\n",
    "    df.rename(columns={\n",
    "        'Bureau of Meteorology station number': \"Station Number\",\n",
    "        'Rainfall amount (millimetres)': 'Rainfall',\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Combine date into a single column.\n",
    "    df['Year'] = df['Year'].map(str)\n",
    "    df['Month'] = df['Month'].map(lambda x: str(x).zfill(2))\n",
    "    df['Day'] = df['Day'].map(lambda x: str(x).zfill(2))\n",
    "    df.insert(\n",
    "        2, 'Date', \n",
    "        df['Year'] + '-' + \n",
    "        df['Month'] + '-' + \n",
    "        df['Day']\n",
    "    )\n",
    "    df.drop(['Year', 'Month', 'Day'], axis=1, inplace=True)\n",
    "\n",
    "    # Next, drop the first and second columns.\n",
    "    df.drop([\"Product code\", \"Station Number\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Drop any rows that are before the start of data collection (i.e. drop Jan if started in Feb).\n",
    "    data_start = df['Rainfall'].first_valid_index()\n",
    "    data_finish = df['Rainfall'].last_valid_index()\n",
    "    df = df[data_start:data_finish]\n",
    "    \n",
    "    # Set the date as the index column.\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Finally return the result.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One big decision I made was to drop the station number as one of the columns in the dataframe. I did this for storage reasons: we don't need the station number repeated 100's of times for no reason. We can store this data some other way.\n",
    "\n",
    "Like per-usual, I'm going to run this on station 9021 to show that the function works and to prepare the data for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Period over which rainfall was measured (days)</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rainfall  Period over which rainfall was measured (days) Quality\n",
       "Date                                                                        \n",
       "2017-12-10       0.0                                             1.0       N\n",
       "2017-12-11       0.0                                             1.0       N\n",
       "2017-12-12       0.0                                             1.0       N\n",
       "2017-12-13       0.0                                             1.0       N\n",
       "2017-12-14       0.0                                             1.0       N"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station9021_df = readStationCSV(glob.glob(\"ExploratoryData/station_9021/*.csv\")[0])\n",
    "station9021_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralising The Data Into One Dataframe\n",
    "This is probably one of the more exciting parts of the notebook. Now that we have the data looking the way we want it to, we can begin to bring multiple station's worth of data together.\n",
    "\n",
    "Since we only have data on station 9021 I'm going to download and clean stations 9022 and 9023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download for station 9022 was successful!\n",
      "Download for station 9023 was successful!\n"
     ]
    }
   ],
   "source": [
    "station_dataframes = [station9021_df]\n",
    "for n in [9022, 9023]:\n",
    "    downloadDataForStation(n, datadir='ExploratoryData/', verbose=True)\n",
    "    unzip('ExploratoryData/station_%s.zip' % n)\n",
    "    station_df = readStationCSV(glob.glob(\"ExploratoryData/station_%s/*.csv\" % n)[0])\n",
    "    station_dataframes.append(station_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously we can visualise each of those dataframes to confirm that they behaved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Rainfall  Period over which rainfall was measured (days) Quality\n",
      "Date                                                                        \n",
      "2017-12-10       0.0                                             1.0       N\n",
      "2017-12-11       0.0                                             1.0       N\n",
      "2017-12-12       0.0                                             1.0       N\n",
      "2017-12-13       0.0                                             1.0       N\n",
      "2017-12-14       0.0                                             1.0       N \n",
      "\n",
      "\n",
      "\n",
      "            Rainfall  Period over which rainfall was measured (days) Quality\n",
      "Date                                                                        \n",
      "1954-06-25       4.3                                             1.0       Y\n",
      "1954-06-26      10.4                                             1.0       Y\n",
      "1954-06-27      22.6                                             1.0       Y\n",
      "1954-06-28      18.0                                             1.0       Y\n",
      "1954-06-29       0.3                                             1.0       Y \n",
      "\n",
      "\n",
      "\n",
      "            Rainfall  Period over which rainfall was measured (days) Quality\n",
      "Date                                                                        \n",
      "2017-12-10       0.0                                             1.0       N\n",
      "2017-12-11       0.0                                             1.0       N\n",
      "2017-12-12       0.0                                             1.0       N\n",
      "2017-12-13       0.0                                             1.0       N\n",
      "2017-12-14       0.0                                             1.0       N \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in station_dataframes:\n",
    "    print n.tail(5), '\\n\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is really exciting. We are going to generate a [MultiIndexed](https://pandas.pydata.org/pandas-docs/stable/advanced.html) dataframe! I do that below using pandas's function [concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pandas.concat(\n",
    "    station_dataframes, \n",
    "    keys=['9021', '9022', '9023'], \n",
    "    names=['Station Number', 'Date']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which does a great job of organising the data. If you'd like to understand how MultiIndexing works, and how to select data using it, just go to the documentation page on [MultiIndex/Advanced Indexing](https://pandas.pydata.org/pandas-docs/stable/advanced.html). I will however give you a taste of the power of MultiIndexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Period over which rainfall was measured (days)</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9022</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Rainfall  Period over which rainfall was measured (days)  \\\n",
       "Station Number                                                             \n",
       "9021                 0.0                                             NaN   \n",
       "9022                 0.0                                             NaN   \n",
       "9023                 0.0                                             NaN   \n",
       "\n",
       "               Quality  \n",
       "Station Number          \n",
       "9021                 Y  \n",
       "9022                 Y  \n",
       "9023                 Y  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.xs('1950-01-01', level='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Period over which rainfall was measured (days)</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station Number</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">9022</th>\n",
       "      <th>1877-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877-01-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">9023</th>\n",
       "      <th>2017-11-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>8.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-05</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77928 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Rainfall  \\\n",
       "Station Number Date                   \n",
       "9022           1877-01-01       0.0   \n",
       "               1877-01-02       0.0   \n",
       "               1877-01-03       0.0   \n",
       "               1877-01-04       0.0   \n",
       "               1877-01-05       0.0   \n",
       "               1877-01-06       0.0   \n",
       "               1877-01-07       0.0   \n",
       "               1877-01-08       0.0   \n",
       "               1877-01-09       0.0   \n",
       "               1877-01-10       0.0   \n",
       "               1877-01-11       0.0   \n",
       "               1877-01-12       0.0   \n",
       "               1877-01-13       0.0   \n",
       "               1877-01-14       0.0   \n",
       "               1877-01-15       0.0   \n",
       "               1877-01-16       0.0   \n",
       "               1877-01-17       0.0   \n",
       "               1877-01-18       0.0   \n",
       "               1877-01-19       0.0   \n",
       "               1877-01-20       0.0   \n",
       "               1877-01-21       0.0   \n",
       "               1877-01-22       0.0   \n",
       "               1877-01-23       0.0   \n",
       "               1877-01-24       0.0   \n",
       "               1877-01-25       0.0   \n",
       "               1877-01-26       0.0   \n",
       "               1877-01-27       0.0   \n",
       "               1877-01-28       0.0   \n",
       "               1877-01-29       0.0   \n",
       "               1877-01-30       0.0   \n",
       "...                             ...   \n",
       "9023           2017-11-15       0.0   \n",
       "               2017-11-16       0.0   \n",
       "               2017-11-17       0.6   \n",
       "               2017-11-18       4.0   \n",
       "               2017-11-19       0.6   \n",
       "               2017-11-20       0.0   \n",
       "               2017-11-21       0.0   \n",
       "               2017-11-22       0.2   \n",
       "               2017-11-23       0.0   \n",
       "               2017-11-24       0.0   \n",
       "               2017-11-25       0.0   \n",
       "               2017-11-26       0.0   \n",
       "               2017-11-27       0.0   \n",
       "               2017-11-28       0.0   \n",
       "               2017-11-29       0.4   \n",
       "               2017-11-30       0.0   \n",
       "               2017-12-01       0.0   \n",
       "               2017-12-02       0.0   \n",
       "               2017-12-03       0.0   \n",
       "               2017-12-04       8.6   \n",
       "               2017-12-05       0.2   \n",
       "               2017-12-06       0.0   \n",
       "               2017-12-07       0.0   \n",
       "               2017-12-08       0.0   \n",
       "               2017-12-09       0.0   \n",
       "               2017-12-10       0.0   \n",
       "               2017-12-11       0.0   \n",
       "               2017-12-12       0.0   \n",
       "               2017-12-13       0.0   \n",
       "               2017-12-14       0.0   \n",
       "\n",
       "                           Period over which rainfall was measured (days)  \\\n",
       "Station Number Date                                                         \n",
       "9022           1877-01-01                                             NaN   \n",
       "               1877-01-02                                             NaN   \n",
       "               1877-01-03                                             NaN   \n",
       "               1877-01-04                                             NaN   \n",
       "               1877-01-05                                             NaN   \n",
       "               1877-01-06                                             NaN   \n",
       "               1877-01-07                                             NaN   \n",
       "               1877-01-08                                             NaN   \n",
       "               1877-01-09                                             NaN   \n",
       "               1877-01-10                                             NaN   \n",
       "               1877-01-11                                             NaN   \n",
       "               1877-01-12                                             NaN   \n",
       "               1877-01-13                                             NaN   \n",
       "               1877-01-14                                             NaN   \n",
       "               1877-01-15                                             NaN   \n",
       "               1877-01-16                                             NaN   \n",
       "               1877-01-17                                             NaN   \n",
       "               1877-01-18                                             NaN   \n",
       "               1877-01-19                                             NaN   \n",
       "               1877-01-20                                             NaN   \n",
       "               1877-01-21                                             NaN   \n",
       "               1877-01-22                                             NaN   \n",
       "               1877-01-23                                             NaN   \n",
       "               1877-01-24                                             NaN   \n",
       "               1877-01-25                                             NaN   \n",
       "               1877-01-26                                             NaN   \n",
       "               1877-01-27                                             NaN   \n",
       "               1877-01-28                                             NaN   \n",
       "               1877-01-29                                             NaN   \n",
       "               1877-01-30                                             NaN   \n",
       "...                                                                   ...   \n",
       "9023           2017-11-15                                             1.0   \n",
       "               2017-11-16                                             1.0   \n",
       "               2017-11-17                                             1.0   \n",
       "               2017-11-18                                             1.0   \n",
       "               2017-11-19                                             1.0   \n",
       "               2017-11-20                                             1.0   \n",
       "               2017-11-21                                             1.0   \n",
       "               2017-11-22                                             1.0   \n",
       "               2017-11-23                                             1.0   \n",
       "               2017-11-24                                             1.0   \n",
       "               2017-11-25                                             1.0   \n",
       "               2017-11-26                                             1.0   \n",
       "               2017-11-27                                             1.0   \n",
       "               2017-11-28                                             1.0   \n",
       "               2017-11-29                                             1.0   \n",
       "               2017-11-30                                             1.0   \n",
       "               2017-12-01                                             1.0   \n",
       "               2017-12-02                                             1.0   \n",
       "               2017-12-03                                             1.0   \n",
       "               2017-12-04                                             1.0   \n",
       "               2017-12-05                                             1.0   \n",
       "               2017-12-06                                             1.0   \n",
       "               2017-12-07                                             1.0   \n",
       "               2017-12-08                                             1.0   \n",
       "               2017-12-09                                             1.0   \n",
       "               2017-12-10                                             1.0   \n",
       "               2017-12-11                                             1.0   \n",
       "               2017-12-12                                             1.0   \n",
       "               2017-12-13                                             1.0   \n",
       "               2017-12-14                                             1.0   \n",
       "\n",
       "                          Quality  \n",
       "Station Number Date                \n",
       "9022           1877-01-01       Y  \n",
       "               1877-01-02       Y  \n",
       "               1877-01-03       Y  \n",
       "               1877-01-04       Y  \n",
       "               1877-01-05       Y  \n",
       "               1877-01-06       Y  \n",
       "               1877-01-07       Y  \n",
       "               1877-01-08       Y  \n",
       "               1877-01-09       Y  \n",
       "               1877-01-10       Y  \n",
       "               1877-01-11       Y  \n",
       "               1877-01-12       Y  \n",
       "               1877-01-13       Y  \n",
       "               1877-01-14       Y  \n",
       "               1877-01-15       Y  \n",
       "               1877-01-16       Y  \n",
       "               1877-01-17       Y  \n",
       "               1877-01-18       Y  \n",
       "               1877-01-19       Y  \n",
       "               1877-01-20       Y  \n",
       "               1877-01-21       Y  \n",
       "               1877-01-22       Y  \n",
       "               1877-01-23       Y  \n",
       "               1877-01-24       Y  \n",
       "               1877-01-25       Y  \n",
       "               1877-01-26       Y  \n",
       "               1877-01-27       Y  \n",
       "               1877-01-28       Y  \n",
       "               1877-01-29       Y  \n",
       "               1877-01-30       Y  \n",
       "...                           ...  \n",
       "9023           2017-11-15       N  \n",
       "               2017-11-16       N  \n",
       "               2017-11-17       N  \n",
       "               2017-11-18       N  \n",
       "               2017-11-19       N  \n",
       "               2017-11-20       N  \n",
       "               2017-11-21       N  \n",
       "               2017-11-22       N  \n",
       "               2017-11-23       N  \n",
       "               2017-11-24       N  \n",
       "               2017-11-25       N  \n",
       "               2017-11-26       N  \n",
       "               2017-11-27       N  \n",
       "               2017-11-28       N  \n",
       "               2017-11-29       N  \n",
       "               2017-11-30       N  \n",
       "               2017-12-01       N  \n",
       "               2017-12-02       N  \n",
       "               2017-12-03       N  \n",
       "               2017-12-04       N  \n",
       "               2017-12-05       N  \n",
       "               2017-12-06       N  \n",
       "               2017-12-07       N  \n",
       "               2017-12-08       N  \n",
       "               2017-12-09       N  \n",
       "               2017-12-10       N  \n",
       "               2017-12-11       N  \n",
       "               2017-12-12       N  \n",
       "               2017-12-13       N  \n",
       "               2017-12-14       N  \n",
       "\n",
       "[77928 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.loc[['9022', '9023']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4 - Export The Data <a name='part4'></a>\n",
    "This section is completely trivial with Pandas. Using the method [to_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html) you can export the entire dataframe into a csv file with almost zero effort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_main.to_csv('ExploratoryData/example_export.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we finish, we want to check that the exported data is formatted correctly. That's a trivial operation in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Number,Date,Rainfall,Period over which rainfall was measured (days),Quality\n",
      "\n",
      "9021,1944-05-01,0.0,,Y\n",
      "\n",
      "9021,1944-05-02,0.0,,Y\n",
      "\n",
      "9021,1944-05-03,0.0,,Y\n",
      "\n",
      "9021,1944-05-04,4.3,1.0,Y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('ExploratoryData/example_export.csv', 'r') as f:\n",
    "    for _ in range(5): print f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also check if it is easily importable back into Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Period over which rainfall was measured (days)</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station Number</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9023</th>\n",
       "      <th>2017-12-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Rainfall  \\\n",
       "Station Number Date                   \n",
       "9023           2017-12-10       0.0   \n",
       "               2017-12-11       0.0   \n",
       "               2017-12-12       0.0   \n",
       "               2017-12-13       0.0   \n",
       "               2017-12-14       0.0   \n",
       "\n",
       "                           Period over which rainfall was measured (days)  \\\n",
       "Station Number Date                                                         \n",
       "9023           2017-12-10                                             1.0   \n",
       "               2017-12-11                                             1.0   \n",
       "               2017-12-12                                             1.0   \n",
       "               2017-12-13                                             1.0   \n",
       "               2017-12-14                                             1.0   \n",
       "\n",
       "                          Quality  \n",
       "Station Number Date                \n",
       "9023           2017-12-10       N  \n",
       "               2017-12-11       N  \n",
       "               2017-12-12       N  \n",
       "               2017-12-13       N  \n",
       "               2017-12-14       N  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importdf2 = pandas.read_csv(\"ExploratoryData/example_export.csv\", index_col=[0, 1])\n",
    "importdf2.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of course it is! Thus we have now successfully exported the data into CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Conclusion <a name='conclusion'></a>\n",
    "\n",
    "As you can see, it is completely viable to extract weather data from BOM using a few simple commands in Python. The process of centralising the data enables others to worry about the nuts-and-bolts of their algorithms, rather then worry about where to find it and how to clean it. Not only can others use the data, but new faces in the data science world can see how easy it is to scrape the internet for data that they can use themselves. Hopefully they will even find out about a couple python packages along the way!\n",
    "\n",
    "The biggest uses for this data would relate to climate change. We can observe the trends in weather in WA (or Australia) and try to predict in what direction our climate is heading. There are other project ideas however: we could measure the viabiliity of getting solar panels in regional areas of WA, the potential savings to be had by installing a water tank onto your house, cleaning up the data using other station's information and many more.\n",
    "\n",
    "The next step is to create the executable file so that I can collect all of the data, rather then just a small sample of it. This is a relatively simple process as I have already figured out most of the functions and packages in this notebook. I'll be also gathering the data for the maximum and minimum temperature plus the solar exposure so there is even more information to work with.\n",
    "\n",
    "In a future project I'll be exploring the data itself. Hopefully I will be able to visualise the rainfall over the past 100 years, build a model that can roughly predict the rainfall at any point in space (i.e. the rainfall at your house which is between three weather stations) and even predict future rainfall patterns.\n",
    "\n",
    "Finally thank you for reading this notebook. Hopefully there was something you learnt from it or it was perhaps just interesting. If you have any comments, recommendations or improvements to anything in this repository feel free to reach out to me or submit a pull request. I'm always happy for others to improve my work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
